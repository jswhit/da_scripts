#!/bin/sh
export OMP_NUM_THREADS=${OMP_NUM_THREADS:-1}
[ -z "$nprocs" ] && echo "Need to set nprocs" && exit 1;
[ -z "$PGM" ] && echo "Need to set PGM" && exit 1;
# use srun
totcores=`expr $nprocs \* $OMP_NUM_THREADS`
totnodes=`python -c "import math; print int(math.ceil(float(${totcores})/${corespernode}))"`
count=`python -c "import math; print int(math.floor(float(${corespernode})/${mpitaskspernode}))"` 
mpitaskspernode=`python -c "import math; print int(math.ceil(float(${nprocs})/${totnodes}))"`
# -c: cpus per mpi task (number of threads per mpi task)
# -n: total number of mpi tasks
# -N: number of nodes to run on
# --ntasks-per-node:  mpi tasks on each node
echo "running srun -N $totnodes -n $nprocs -c $count --ntasks-per-node=$mpitaskspernode  --exclusive --cpu-bind=cores --verbose $PGM"
eval srun -N $totnodes -n $nprocs -c $count --ntasks-per-node=$mpitaskspernode --exclusive --cpu-bind=cores --verbose $PGM
rc=$?
echo "exiting runmpi..."
exit $rc
